<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CookCv - deeplearning</title><meta name="description" content="深度学习视觉"><meta name="keywords" content="‘computer vision’"><meta name="author" content="Kai Chen"><meta name="copyright" content="Kai Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://cookcv.com/page/7/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="website"><meta property="og:title" content="CookCv"><meta property="og:url" content="http://cookcv.com/page/7/"><meta property="og:site_name" content="CookCv"><meta property="og:description" content="深度学习视觉"><meta property="og:image" content="http://cookcv.com/null"><meta property="article:published_time" content="2020-09-20T09:32:38.501Z"><meta property="article:modified_time" content="2020-09-20T09:32:38.501Z"><meta name="twitter:card" content="summary"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime: '',
  date_suffix: {"one_hour":"刚刚","hours":"小时前","day":"天前"},
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
    },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-09-20 17:32:38'
}</script><noscript><style type="text/css">
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
  }
}

var autoChangeMode = 'false'
var t = saveToLocal.get('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (saveToLocal.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">70</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">91</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-link"></i><span> 留言板</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">CookCv</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-link"></i><span> 留言板</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site_title">CookCv</h1><div id="site_subtitle"><span id="subtitle"></span></div></div><div id="scroll_down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/ea81a742.html" title="积分图与BoxFilter滤波">积分图与BoxFilter滤波</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV/">计算机视觉CV</a></span></div><div class="content">简介 积分图的出现使得Haar特征的计算更为高效，这是一种动态规划算法，以减少重复计算缩减算法时间。它可以使复杂度为O(MN)的求和，求方差等运算降低到O(4)的复杂度，而BoxFilter可以降到O(1)，不过BoxFilter不支持多尺度。 
积分图的缺陷 因为一直在累加，所以，当原图很大的话，会出现溢出的情况，所以，不建议使用int64等类型。
积分图讲解： 积分图中任意位置的值是由原图中该位置和其左上角所有位置值的和。 每一点\(I(x,y)\)的计算公式为： \(I(x,y) = i(x,y) + I(x-1,y) + I(x,y-1) - I(x-1,y-1)\)


当得到积分图之后，阴影区域的和即可计算得到。该阴影矩形可以是任意形状。 \[\sum_{A(x)&lt;x^{\prime} \leq C(x) \atop A(y)&lt;y^{\prime} \leq C(y)} i\left(x^{\prime}, y^{\prime}\right)=I(C_{right\_bottom})+I(A_{right\_bottom})-I(B_{right\_bottom ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/708eb5b2.html" title="粗糙集理论学习笔记">粗糙集理论学习笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">粗糙集理论的主要思想是利用已知的知识库，将不精确或不确定的知识用已知的知识库中的知识来（近似）刻画。 

基本粗糙集理论的主要存在的问题： 1）对原始数据本身的模糊性缺乏相应的处理能力； 2）对于粗糙集的边界区域的刻画过于简单； 3）粗糙集理论的方法在可用信息不完全的情况下将对象们归类于某一具体的类，通常分类是确定的，但并未提供数理统计中所常用的在一个给定错误率的条件下将尽可能多的对象进行分类的方法，而实际中常常遇到这类问题。

该理论与其他处理不确定和不精确问题理论的最显著的区别是它无需提供问题所需处理的数据集合之外的任何先验信息，所以对问题的不确定性的描述或处理可以说比较客观。

论域：包含若干对象的非空有限集。 概念：任意集合X属于论域U为一个概念。 空概念：一个空集视为空概念。 知识：由任意个这样的X组成的自己簇形成了论域中抽象知识，是一种能力，用来分类对象。 对象：任何实体，物品、属性、概率等。 不可定义集：对于论域U上任意一个子集X，X不一定能用知识库中的知识来精确表达。

信息系统四元组（U,Q,V,f），其中 U是对象集合， Q是属性集合（包括条件属性C和决策属性D）， ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/658633c0.html" title="罗尔中值, 拉格朗日中值, 柯西中值">罗尔中值, 拉格朗日中值, 柯西中值</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">简述： 罗尔==&gt;拉格朗日==&gt;柯西，特殊性逐渐渐减弱。 
罗尔中值定理： 一个物体往返运动时，一定有一点的瞬时速度为0。 如果函数f(x)满足（1）在闭区间[a,b]上连续；（2）在(a,b)内可导；（3）f(a)=f(b)，则至少存在一个\(\xi \in(a, b)\)，使得\(f^{\prime}(\xi)=0\)。 
拉格朗日中值定理： 在a,b之间一定能够找到一个瞬时速度等于这两点之间的平均速度。 如果函数f(x)满足以下条件，（1）在闭区间[a,b]上连续；（2）在(a,b)内可导；（3）那么存在一点\(\xi \in(a, b)\)，使得等式\(f^{\prime}(\xi)=\frac{f(b)-f(a)}{b-a}\)成立。 
柯西中值定理： 两个物体时间相同下，即使速度不同，也会存在一点，瞬时速度的比值等于平均速度的比值。 如果函数f(x)与g(x)满足以下条件，（1）在闭区间[a,b]上连续；（2）z在(a,b)内可导；（3）对任意\(x \in(a, b), g^{\prime}(x) \neq 0\)则在(a,b)内至少存在一点\(\xi\)，使 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/a3b3b417.html" title="范数介绍">范数介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">向量范数： 向量范数定义了向量的距离，而距离满足正定，齐次，三角不等式。范数的使用可以帮助特征选择，使得模型更具解释性。  向量的范数一般有L0, L1, L2与L_infinity范数,
L0范数： 定义：\(\|x\|_{0}=\sum_{i=1}^{k}\left|x_{i}\right|^{0}\) L0范数表示非0元素的个数。利用该特性，我们可以用来规则化机器学习中的参数w，可以使得w大部分元素为零，寻找最少最优的稀疏特征。但是，L0范数的最小化问题是NP难问题，而L1范数是L0范数的最优凸近似，L1范数比L0范数更容易求解。所以实际中会用L1范数来代替L0范数求解。
L1范数： 定义：\(\|x\|_{1}=\sum_{i=1}^{k}\left|x_{i}\right|\) L1范数表示向量中各个元素绝对值的和，也被称作&quot;Lasso regularization&quot;(稀疏规则算子)。在机器学习中，稀疏规则化能够实现特征的自动选择，将无用的特征权重置为0来剔除。
L2范数： 定义：\(\|x\|_{2}=\sqrt{\sum_{i=1}^{k}\left| ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/e5c13f51.html" title="谱聚类学习">谱聚类学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">简介

方阵作为线性算子，它的所有征值的全体统方阵的谱。
方阵的谱半径为最大的特征值；
矩阵A的谱半径：(ATA)的最大特征值；
谱聚类：是一种基于图的聚类方法，通过对样本数据的拉普拉斯矩阵的特征向量进行聚类，从而达到对样本聚类的目的。 

基础概念
无向图：G=(V,E) 邻接矩阵：\(W=(w_{ij})i,j=1,...,n\)，对称阵。 顶点的度：对角矩阵D,\(d_i=\sum^n_{j=1}w_{ij}\)表示某个顶点，所有与它连接的相似度和。
谱分析的整体过程

计算数据彼此之间的相似度，构成相似度矩阵(相似度图)。（关于相似度的计算可以用欧式距离，也可以用高斯函数。）
接下来，用相似度图来解决样本数据的聚类问题。找到图的一个划分，形成若干个组（Group）,使得不同组之间有较低的权值，组内有较高的权值。

</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/2a97a967.html" title="逻辑回归介绍">逻辑回归介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">


线性回归模型公式：\(g(x)=\omega_{0}+\omega_{1} x_{1}\)
逻辑回归模型公式：\(f(x)=\frac{1}{1+e^{-g(x)}}\)（包含了线性回归）
在\(x\)条件下\(y=1\)发生的概率为：\(P(y=1 | x)=\pi(x)=\frac{1}{1+e^{-g(x)}}\)
在\(x\)条件下\(y = 1\)不发生的概率为：\(P(y=0 | x)=1-P(y=1 | x)=1-\frac{1}{1+e^{-g(x)}}=\frac{e^{-g(x)}}{1+e^{-g(x)}}=\frac{1}{1+e^{g(x)}}\)
事件发生与不发生的概率比（事件发生比odds）为：\(\frac{P(y=1 | x)}{P(y=0 | x)}=\frac{p}{1-p}=e^{g(x)}\)
接下来将会对这个odds进行操作。
设非线性函数\(g(x)=w_{0}+w_{1} x_{1}+\ldots+w_{n} x_{n}\)
对odds取对数得到：\(\ln \left(\frac{p}{1-p}\right)=g(x)=w_{0} ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/c397a88b.html" title="采样的作用">采样的作用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">定义： 采样本质上是对随机现象的模拟，根据给定的概率分布，来模拟产生一个对应的随机事件。采样可以让人们对随机事件及其产生过程有更直观的认识。
实例：通过对二项分布的采样，可以模拟”抛硬币出现正面还是反面“这个随机事件，进而模拟产生一个多次抛硬币出现的序列。 
采样的作用：
1.采样也是一种信息降维，可以起到简化问题的作用。
2.采样得到的样本集可以看作是一种非参数模型，即用较少量的样本点（经验分布）来近似总体分布，并刻画分布中的不确定性。
3.采样这种信息降维的特性，可以帮助人们快速、直观地了解总体分布中数据的结构核特性。
4.利用重采样可以保持特定的信息下（目标信息不丢失），有意识地改变改变样本的分布，以更适应后续模型的训练和学习，比如用重采样来处理分类模型的训练样本不均衡的问题。
5.很多模型由于结构复杂、含有隐变量等原因，导致对应的求解公式比较复杂，没有显示解析解，难以进行精确求解或推理。这种情况下可以利用采样的方法进行随机模拟，从而对这些复杂模型进行近似求解或推理。
</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/34933be3.html" title="隐马尔可夫模型HMM学习笔记">隐马尔可夫模型HMM学习笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">


一个模型 HMM定义为\(\lambda = (N,M,\pi,A,B)\)
N：模型中马尔可夫链的状态数目\([s_1,s_2,...,s_N]\)。如果记t时刻Markov链所处的状态\(q_t\)，那么\(q_t \in (s_1,s_2,...,s_N)\)。
M：每个状态可能输出的观测符号数目\([\theta_1,\theta_2,...,\theta_M]\)。如果记t时刻Markov链所处的观测值维\(O_t\)，那么\(O_t \in (\theta_1,\theta_2,...,\theta_M)\)。
\(\pi\)：初始状态概率分布矢量，\(\pi = (\pi_1,\pi_2,...,\pi_N)\)。某一时刻处于某一状态的概率。$= P(q_t=s_i),1 i N $。
A：状态转移概率矩阵。\(A=\{ a_{ij} \}_{NN}\) 。\(a_ij = P(q_{t+1}=s_j,q_t = s_i);1\leq i,j\leq N\)表示两个状态之间的转移概率。
B：观测符号概率分布，\(B = \{ b_j(k)\}_{NM}\)。其中：\ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/8edc4196.html" title="马尔可夫链介绍">马尔可夫链介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">简介
马尔可夫链（Markov chain），又称离散时间马尔可夫链（discrete-time Markov chain）为状态空间中经过从一个状态到另一个状态的转换的随机过程。
该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作马尔可夫性质。
在马尔可夫链的每一步，系统根据概率分布，可以从一个状态变到另一个状态，也可以保持当前状态。状态的改变叫做转移，与不同的状态改变相关的概率叫做转移概率。
随机漫步就是马尔可夫链的例子。随机漫步中每一步的状态是在图形中的点，每一步可以移动到任何一个相邻的点，在这里移动到每一个点的概率都是相同的（无论之前漫步路径是如何的）。【维基百科】 

马尔可夫链动图.gif

马尔可夫链的数学表示为： \(P\left(x_{t+1} | \cdots, x_{t-2}, x_{t-1}, x_{t}\right)=P\left(x_{t+1} | x_{t}\right)\) 既然某一时刻状态转移的概率只依赖前一个状态，那么只要求出系统中任意两个状态之间的转移概率，这个马 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info"><a class="article-title" href="/blog/2f062e4e.html" title="高斯混合模型">高斯混合模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-12-31T17:01:01.000Z" title="发表于 2020-01-01 01:01:01">2020-01-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">简述： 高斯混合模型是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代。高斯混合模型假设每个簇的数据都是符合高斯分布的，当前数据呈现的分布就是各个簇的高斯分布叠加在一起的效果，可用多个高斯分布函数的线性组合来对数据分布进行拟合。理论上，高斯混合模型可以拟合出任意类型的分布。 
公式解说： GMM的概率密度函数：\(p(x)=\sum_{k=1}^{K} p(k) p(x | k)=\sum_{k=1}^{K} \pi_{k} N\left(x | u_{k}, \Sigma_{k}\right)\) 其中\(p(x | k)=N\left(x | u_{k}, \Sigma_{k}\right)\)是第k个高斯模型的概率密度函数，指的是选定第k个模型后产生x的概率，\(p(k)=\pi_{k}\)是第k个高斯模型的权重，称作选择第k个模型的先验概率，且满足\(\sum_{k=1}^{K} \pi_{k}=1\) 。
GMM的意义： 比如一个班级所有同学的身高可以看作一个高斯分布，但是，一个高斯分布难免会欠拟合。所以，将维度变为2，拆分为男女两部分数据，用两个高斯模型共同 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/6/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Kai Chen</div><div class="author-info__description">深度学习视觉</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length_num">70</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length_num">91</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length_num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="sticky_layout"><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><div class="content"><a class="title" href="/blog/5566fb07.html" title="Text Summarization">Text Summarization</a><time datetime="2020-03-11T17:01:01.000Z" title="发表于 2020-03-12 01:01:01">2020-03-12</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/blog/4f7ea913.html" title="CNN如何学到图片中的位置信息">CNN如何学到图片中的位置信息</a><time datetime="2020-03-04T17:01:01.000Z" title="发表于 2020-03-05 01:01:01">2020-03-05</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/blog/1b2588a1.html" title="TFLite安卓项目解读">TFLite安卓项目解读</a><time datetime="2020-03-04T17:01:01.000Z" title="发表于 2020-03-05 01:01:01">2020-03-05</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/blog/3b862564.html" title="字向量的产生">字向量的产生</a><time datetime="2020-03-04T17:01:01.000Z" title="发表于 2020-03-05 01:01:01">2020-03-05</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/blog/393c1f25.html" title="差异分析">差异分析</a><time datetime="2020-03-04T17:01:01.000Z" title="发表于 2020-03-05 01:01:01">2020-03-05</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LeetCode/"><span class="card-category-list-name">LeetCode</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">40</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%83%A8%E7%BD%B2/"><span class="card-category-list-name">深度学习部署</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/"><span class="card-category-list-name">自然语言处理NLP</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV/"><span class="card-category-list-name">计算机视觉CV</span><span class="card-category-list-count">21</span></a></li>
            
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Anchor/" style="font-size: 1.1em; color: #999">Anchor</a> <a href="/tags/Attention/" style="font-size: 1.1em; color: #999">Attention</a> <a href="/tags/Bagging/" style="font-size: 1.1em; color: #999">Bagging</a> <a href="/tags/Bayes/" style="font-size: 1.1em; color: #999">Bayes</a> <a href="/tags/Beta%E5%88%86%E5%B8%83/" style="font-size: 1.1em; color: #999">Beta分布</a> <a href="/tags/Boosting/" style="font-size: 1.1em; color: #999">Boosting</a> <a href="/tags/CNN/" style="font-size: 1.1em; color: #999">CNN</a> <a href="/tags/FasterRCNN/" style="font-size: 1.1em; color: #999">FasterRCNN</a> <a href="/tags/GAN/" style="font-size: 1.1em; color: #999">GAN</a> <a href="/tags/HMM/" style="font-size: 1.3em; color: #99a1ac">HMM</a> <a href="/tags/Haar/" style="font-size: 1.1em; color: #999">Haar</a> <a href="/tags/IOU/" style="font-size: 1.1em; color: #999">IOU</a> <a href="/tags/LGSPP/" style="font-size: 1.1em; color: #999">LGSPP</a> <a href="/tags/LOSS/" style="font-size: 1.3em; color: #99a1ac">LOSS</a> <a href="/tags/LSTM/" style="font-size: 1.1em; color: #999">LSTM</a> <a href="/tags/NP%E9%97%AE%E9%A2%98/" style="font-size: 1.1em; color: #999">NP问题</a> <a href="/tags/PCA/" style="font-size: 1.1em; color: #999">PCA</a> <a href="/tags/Python/" style="font-size: 1.3em; color: #99a1ac">Python</a> <a href="/tags/TFLite/" style="font-size: 1.1em; color: #999">TFLite</a> <a href="/tags/Text-Summarization/" style="font-size: 1.1em; color: #999">Text Summarization</a> <a href="/tags/Word2Vec/" style="font-size: 1.1em; color: #999">Word2Vec</a> <a href="/tags/XGBoost/" style="font-size: 1.1em; color: #999">XGBoost</a> <a href="/tags/mmdetection/" style="font-size: 1.1em; color: #999">mmdetection</a> <a href="/tags/one-hot/" style="font-size: 1.1em; color: #999">one hot</a> <a href="/tags/%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/" style="font-size: 1.1em; color: #999">中值定理</a> <a href="/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" style="font-size: 1.1em; color: #999">主成分分析</a> <a href="/tags/%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83/" style="font-size: 1.1em; color: #999">二项分布</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">人脸检测</a> <a href="/tags/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83/" style="font-size: 1.1em; color: #999">伯努利分布</a> <a href="/tags/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/" style="font-size: 1.1em; color: #999">似然函数</a> <a href="/tags/%E4%BD%99%E5%BC%A6%E8%B7%9D%E7%A6%BB/" style="font-size: 1.1em; color: #999">余弦距离</a> <a href="/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" style="font-size: 1.1em; color: #999">假设检验</a> <a href="/tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99/" style="font-size: 1.1em; color: #999">关联规则</a> <a href="/tags/%E5%86%B3%E7%AD%96/" style="font-size: 1.1em; color: #999">决策</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 1.5em; color: #99a9bf">决策树</a> <a href="/tags/%E5%87%B8%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">凸优化</a> <a href="/tags/%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1/" style="font-size: 1.1em; color: #999">分类损失</a> <a href="/tags/%E5%8D%B7%E7%A7%AF/" style="font-size: 1.1em; color: #999">卷积</a> <a href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/" style="font-size: 1.1em; color: #999">可视化工具</a> <a href="/tags/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/" style="font-size: 1.3em; color: #99a1ac">命名实体识别</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/03/"><span class="card-archive-list-date">三月 2020</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/01/"><span class="card-archive-list-date">一月 2020</span><span class="card-archive-list-count">59</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">70</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2020-09-20T09:32:38.264Z"></div></div></div></div></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Kai Chen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>